{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b8c7bc-5130-47e9-8701-29f4adbfc242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDecision tree classification is used for classification problems.\\nDecision trees are used as an approach in machine learning to structure the algorithm.\\nA decision tree algorithm will be used to split dataset features through a cost function. \\nThe decision tree is grown before being optimised to remove branches that may use irrelevant\\nfeatures, a process called pruning.\\n\\nIn Decision Trees, for predicting a class label for a record we start from the root of the tree. \\nWe compare the values of the root attribute with the record's attribute. On the basis of comparison,\\nwe follow the branch corresponding to that value and jump to the next node.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 1 :\n",
    "\"\"\"\n",
    "Decision tree classification is used for classification problems.\n",
    "Decision trees are used as an approach in machine learning to structure the algorithm.\n",
    "A decision tree algorithm will be used to split dataset features through a cost function. \n",
    "The decision tree is grown before being optimised to remove branches that may use irrelevant\n",
    "features, a process called pruning.\n",
    "\n",
    "In Decision Trees, for predicting a class label for a record we start from the root of the tree. \n",
    "We compare the values of the root attribute with the record's attribute. On the basis of comparison,\n",
    "we follow the branch corresponding to that value and jump to the next node.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0fe953-c13b-46d3-88ba-afdd756d8792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFirst, we calculate the percentage of records that fall into each class (p). \\nThen we square those numbers and add them together. Finally, we subtract that number from one.\\nBecause decision trees split data into more than one group, our final step is to calculate the weighted\\naverage of the Gini Impurity in each group.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 2 : \n",
    "\"\"\"\n",
    "First, we calculate the percentage of records that fall into each class (p). \n",
    "Then we square those numbers and add them together. Finally, we subtract that number from one.\n",
    "Because decision trees split data into more than one group, our final step is to calculate the weighted\n",
    "average of the Gini Impurity in each group.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1964cfe7-9fa8-4df0-a25e-f30bf6146197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nA Binary Decision Tree is a structure based on a sequential decision process. \\nStarting from the root, a feature is evaluated and one of the two branches is selected.\\nThis procedure is repeated until a final leaf is reached, which normally represents the classification target you're looking for\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q no. 3 :\n",
    "\"\"\"\n",
    "A Binary Decision Tree is a structure based on a sequential decision process. \n",
    "Starting from the root, a feature is evaluated and one of the two branches is selected.\n",
    "This procedure is repeated until a final leaf is reached, which normally represents the classification target you're looking for\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e408d77a-eaf2-4eb0-9fd2-7c9f9d2e7b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA decision node, represented by a square, shows a decision to be made, and an end node \\nshows the final outcome of a decision path.\\nDecision trees can also be drawn with flowchart symbols, which some people find easier to read and understand.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "A decision node, represented by a square, shows a decision to be made, and an end node \n",
    "shows the final outcome of a decision path.\n",
    "Decision trees can also be drawn with flowchart symbols, which some people find easier to read and understand.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78ee976-b7bc-4e02-9c09-2b8e799fe1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, \\nwhere N is the total number of target classes. \\nThe matrix compares the actual target values with those predicted by the machine learning model.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "\"\"\"\n",
    "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, \n",
    "where N is the total number of target classes. \n",
    "The matrix compares the actual target values with those predicted by the machine learning model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9368536-5710-43ce-93ec-ded968e357fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExample :A machine learning model is trained to predict tumor in patients. The test dataset consists of 100 people.\\n\\nConfusion Matrix for tumor detection\\nTrue Positive (TP) — model correctly predicts the positive class (prediction and actual both are positive). \\nIn the above example, 10 people who have tumors are predicted positively by the model.\\nTrue Negative (TN) — model correctly predicts the negative class (prediction and actual both are negative). \\nIn the above example, 60 people who don’t have tumors are predicted negatively by the model.\\nFalse Positive (FP) — model gives the wrong prediction of the negative class (predicted-positive, actual-negative). \\nIn the above example, 22 people are predicted as positive of having a tumor, although they don’t have a tumor.\\nFP is also called a TYPE I error.\\nFalse Negative (FN) — model wrongly predicts the positive class (predicted-negative, actual-positive). \\nIn the above example, 8 people who have tumors are predicted as negative. FN is also called a TYPE II error\\n\\nprecision :\\nOut of all the positive predicted, what percentage is truly positive.\\nThe precision value lies between 0 and 1.\\nprecision =TP/FP+TP\\n\\nRecall :\\nOut of the total positive, what percentage are predicted positive. It is the same as TPR (true positive rate).\\nrecall =TP/TP+FN\\nF1 score\\nIt is the harmonic mean of precision and recall. \\nIt takes both false positive and false negatives into account. Therefore, it performs well on an imbalanced dataset.\\nF1 score= 2* (P*R)/(P+R)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "Example :A machine learning model is trained to predict tumor in patients. The test dataset consists of 100 people.\n",
    "\n",
    "Confusion Matrix for tumor detection\n",
    "True Positive (TP) — model correctly predicts the positive class (prediction and actual both are positive). \n",
    "In the above example, 10 people who have tumors are predicted positively by the model.\n",
    "True Negative (TN) — model correctly predicts the negative class (prediction and actual both are negative). \n",
    "In the above example, 60 people who don’t have tumors are predicted negatively by the model.\n",
    "False Positive (FP) — model gives the wrong prediction of the negative class (predicted-positive, actual-negative). \n",
    "In the above example, 22 people are predicted as positive of having a tumor, although they don’t have a tumor.\n",
    "FP is also called a TYPE I error.\n",
    "False Negative (FN) — model wrongly predicts the positive class (predicted-negative, actual-positive). \n",
    "In the above example, 8 people who have tumors are predicted as negative. FN is also called a TYPE II error\n",
    "\n",
    "precision :\n",
    "Out of all the positive predicted, what percentage is truly positive.\n",
    "The precision value lies between 0 and 1.\n",
    "precision =TP/FP+TP\n",
    "\n",
    "Recall :\n",
    "Out of the total positive, what percentage are predicted positive. It is the same as TPR (true positive rate).\n",
    "recall =TP/TP+FN\n",
    "F1 score\n",
    "It is the harmonic mean of precision and recall. \n",
    "It takes both false positive and false negatives into account. Therefore, it performs well on an imbalanced dataset.\n",
    "F1 score= 2* (P*R)/(P+R)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab932354-f735-45e8-b21a-d68362b344fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEvaluation metrics are used to measure the quality of the statistical or machine learning model.\\nEvaluating machine learning models or algorithms is essential for any project. \\nThere are many different types of evaluation metrics available to test a model.\\n\\nAccuracy, confusion matrix, log-loss, and AUC-ROC are some of the most popular metrics.\\nPrecision-recall is a widely used metrics for classification problems.\\n\\nArea Under Curve(AUC) is one of the most widely used metrics for evaluation. \\nIt is used for binary classification problem. \\nAUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive \\nexample higher than a randomly chosen negative example.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "\"\"\"\n",
    "Evaluation metrics are used to measure the quality of the statistical or machine learning model.\n",
    "Evaluating machine learning models or algorithms is essential for any project. \n",
    "There are many different types of evaluation metrics available to test a model.\n",
    "\n",
    "Accuracy, confusion matrix, log-loss, and AUC-ROC are some of the most popular metrics.\n",
    "Precision-recall is a widely used metrics for classification problems.\n",
    "\n",
    "Area Under Curve(AUC) is one of the most widely used metrics for evaluation. \n",
    "It is used for binary classification problem. \n",
    "AUC of a classifier is equal to the probability that the classifier will rank a randomly chosen positive \n",
    "example higher than a randomly chosen negative example.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337bfe64-9e43-41b6-852b-fe054f0b2bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEmail Spam detection:\\nThis is one of the example where Precision is more important than Recall.\\nPrecision: This tells when you predict something positive, how many times they were actually positive.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 8 :\n",
    "\"\"\"\n",
    "Email Spam detection:\n",
    "This is one of the example where Precision is more important than Recall.\n",
    "Precision: This tells when you predict something positive, how many times they were actually positive.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f74604-314e-45cb-b9ee-578d7b7e7352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnother example would be hiring when there are a lot of similar candidates. \\nRecall is more important than precision when the cost of acting is low, but the opportunity cost \\nof passing up on a candidate is high.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "\"\"\"\n",
    "Another example would be hiring when there are a lot of similar candidates. \n",
    "Recall is more important than precision when the cost of acting is low, but the opportunity cost \n",
    "of passing up on a candidate is high.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
